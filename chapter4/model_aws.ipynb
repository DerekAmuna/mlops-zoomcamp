{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dont forget to update pipenv with mlflow and the other packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.ChunkedArray size changed, may indicate binary incompatibility. Expected 64 from C header, got 72 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib._Tabular size changed, may indicate binary incompatibility. Expected 24 from C header, got 32 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.Table size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"PULocationID\", \"DOLocationID\"]\n",
    "numerics = [\"trip_distance\"]\n",
    "target = [\"duration\"]\n",
    "\n",
    "\n",
    "def read_data(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "    df[\"tpep_pickup_datetime\"] = pd.to_datetime(df[\"tpep_pickup_datetime\"])\n",
    "    df[\"tpep_dropoff_datetime\"] = pd.to_datetime(df[\"tpep_dropoff_datetime\"])\n",
    "\n",
    "    df[\"duration\"] = df[\"tpep_dropoff_datetime\"] - df[\"tpep_pickup_datetime\"]\n",
    "    df[\"duration\"] = df[\"duration\"].map(lambda x: x.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df[\"duration\"] >= 0) & (df[\"duration\"] <= 60)]\n",
    "    df[categories] = df[categories].astype(object)\n",
    "\n",
    "    df[\"tpep_pickup_datetime\"] = df[\"tpep_pickup_datetime\"].astype(int)\n",
    "\n",
    "    prepped = df[categories + numerics + target].dropna()\n",
    "    return prepped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data(\"webservice/data/yellow_tripdata_2024-08.parquet\")\n",
    "x_train = df[categories + numerics].to_dict(orient=\"records\")\n",
    "y_train = df[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = read_data(\"webservice/data/yellow_tripdata_2024-01.parquet\")\n",
    "x_test = test_data[categories + numerics].to_dict(orient=\"records\")\n",
    "y_test = test_data[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline = make_pipeline(DictVectorizer(), LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/10 11:31:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/10 11:31:11 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run thundering-toad-387 at: http://127.0.0.1:5000/#/experiments/1/runs/e308ab2a149249a4b161cb428b4abc23.\n",
      "2024/11/10 11:31:11 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: e308ab2a149249a4b161cb428b4abc23\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n",
    "mlflow.set_experiment(\"duration-prediction\")\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "\n",
    "    train_pipeline.fit(x_train, y_train)\n",
    "\n",
    "    # Log metrics\n",
    "    y_pred = train_pipeline.predict(x_test)\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # Log model and DictVectorizer\n",
    "    mlflow.sklearn.log_model(train_pipeline, \"model\")\n",
    "\n",
    "    print(f\"Run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
